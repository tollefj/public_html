{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "download a wrapper for the API, in this case in python: `pip install ollama`\n",
    "\n",
    "we then define our model as a variable and verify its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general.architecture: llama\n",
      "general.basename: Llama-3.2\n",
      "general.file_type: 18\n",
      "general.finetune: Instruct\n",
      "general.languages: ['en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th']\n",
      "general.license: llama3.2\n",
      "general.parameter_count: 1235814432\n",
      "general.quantization_version: 2\n",
      "general.size_label: 1B\n",
      "general.tags: ['facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation']\n",
      "general.type: model\n",
      "llama.attention.head_count: 32\n",
      "llama.attention.head_count_kv: 8\n",
      "llama.attention.key_length: 64\n",
      "llama.attention.layer_norm_rms_epsilon: 1e-05\n",
      "llama.attention.value_length: 64\n",
      "llama.block_count: 16\n",
      "llama.context_length: 131072\n",
      "llama.embedding_length: 2048\n",
      "llama.feed_forward_length: 8192\n",
      "llama.rope.dimension_count: 64\n",
      "llama.rope.freq_base: 500000\n",
      "llama.vocab_size: 128256\n",
      "quantize.imatrix.chunks_count: 125\n",
      "quantize.imatrix.dataset: /training_dir/calibration_datav3.txt\n",
      "quantize.imatrix.entries_count: 112\n",
      "quantize.imatrix.file: /models_out/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.imatrix\n",
      "tokenizer.ggml.bos_token_id: 128000\n",
      "tokenizer.ggml.eos_token_id: 128009\n",
      "tokenizer.ggml.merges: None\n",
      "tokenizer.ggml.model: gpt2\n",
      "tokenizer.ggml.pre: llama-bpe\n",
      "tokenizer.ggml.token_type: None\n",
      "tokenizer.ggml.tokens: None\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "model = \"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:Q6_K_L\"\n",
    "info = ollama.show(model).modelinfo\n",
    "for k, v in info.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple recipe for a delicious citrusy cake that uses metric units and Celsius temperatures:\n",
      "\n",
      "**Citrusy Lemon Cake Recipe**\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 250g all-purpose flour\n",
      "* 150g granulated sugar\n",
      "* 30g unsalted butter, softened\n",
      "* 2 large eggs\n",
      "* 20g freshly squeezed lemon juice (about 1/4 of a medium-sized lemon)\n",
      "* 10g grated lemon zest\n",
      "* 5g baking powder\n",
      "* 3g salt\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 200°C (180°C fan-forced).\n",
      "2. Grease and flour two 20cm round cake pans.\n",
      "3. In a medium bowl, whisk together the flour, sugar, and baking powder.\n",
      "4. In a large bowl, using an electric mixer, beat the butter until creamy. Add eggs one at a time, beating well after each addition.\n",
      "5. Gradually add the dry ingredients to the wet ingredients, alternating with lemon juice and zest, beginning and ending with the dry ingredients. Beat just until combined.\n",
      "6. Divide the batter evenly between the prepared pans and smooth the tops.\n",
      "7. Bake for 25-30 minutes or until a toothpick inserted into the center of each cake comes out clean.\n",
      "\n",
      "**Tips:**\n",
      "\n",
      "* Make sure to use fresh lemons, as they will give the best flavor and texture in your cake.\n",
      "* Don't overmix the batter, as this can result in a dense cake.\n",
      "* If you prefer a stronger lemon flavor, you can increase the amount of lemon juice to 1/2 cup or more.\n",
      "\n",
      "**Enjoy your delicious citrusy cake!**\n",
      "\n",
      "Note: As this is a basic recipe, I didn't include any frosting or decorations. Feel free to get creative and add your favorite toppings once you've made the cake!\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "prompt = \"Give me a simple recipe for a delicious citrusy cake. Make sure units are in grams when it makes sense. Temperatures should be in C.\"\n",
    "\n",
    "response = chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the responses...\n",
    "\n",
    "Can only do so much with raw text... Let's up the controllability!\n",
    "\n",
    "First off, there are a few common parameters that can be used to tune the outputs.\n",
    "Some are related to \"creativity\", whereas some control the predictability and determinism of the outputs.\n",
    "\n",
    "```python\n",
    "\"num_ctx\": \"Maximum number of tokens the model can process in a single input.\"\n",
    "\"seed\": \"Random seed for deterministic generation.\"\n",
    "\"num_predict\": \"Maximum number of tokens to generate in output.\"\n",
    "\"top_k\": \"Limits sampling to the top K most probable tokens.\"\n",
    "\"top_p\": \"Limits sampling to the smallest set of tokens with cumulative probability >= top_p.\"\n",
    "\"temperature\": \"Controls randomness in generation; higher values increase randomness.\"\n",
    "\"repeat_penalty\": \"Penalty for repeated tokens to reduce repetition in output.\"\n",
    "```\n",
    "\n",
    "We can also add a system prompt (see the `role` in the messages below) to guide the model in the right direction. Being explicit on its role can help both the behavior and output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"recipe\": {\n",
      "    \"name\": \"Citrusy Cake\",\n",
      "    \"ingredients\": [\n",
      "      {\n",
      "        \"name\": \"Flour\",\n",
      "        \"quantity\": 250g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Sugar\",\n",
      "        \"quantity\": 200g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Baking powder\",\n",
      "        \"quantity\": 5g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Salt\",\n",
      "        \"quantity\": 2g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Butter\",\n",
      "        \"quantity\": 100g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Eggs\",\n",
      "        \"quantity\": 4,\n",
      "        \"unit\": \"units\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Milk\",\n",
      "        \"quantity\": 250g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Zest of 1 orange\",\n",
      "        \"quantity\": 20g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Zest of 1 lemon\",\n",
      "        \"quantity\": 15g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Juice of 1 lemon\",\n",
      "        \"quantity\": 30g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Juice of 1 orange\",\n",
      "        \"quantity\": 30g,\n",
      "        \"unit\": \"grams\"\n",
      "      }\n",
      "    ],\n",
      "    \"instructions\": [\n",
      "      {\n",
      "        \"step\": \"Preheat oven to 180°C\",\n",
      "        \"description\": \"Preheat oven to 180°C\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Mix dry ingredients\",\n",
      "        \"description\": \"Mix flour, sugar, baking powder, and salt\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Mix wet ingredients\",\n",
      "        \"description\": \"Mix butter, eggs, milk, orange zest, lemon zest, lemon juice, and orange juice\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Combine wet and dry ingredients\",\n",
      "        \"description\": \"Combine wet and dry ingredients\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Pour batter into a greased cake pan\",\n",
      "        \"description\": \"Pour batter into a greased cake pan\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Bake for 35-40 minutes\",\n",
      "        \"description\": \"Bake for 35-40 minutes\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ollama import ChatResponse, chat\n",
    "from pydantic.types import JsonSchemaValue\n",
    "from typing import Optional, List\n",
    "\n",
    "system_prompt = \"You are a helpful assistant that provides clear and concise answers to the user's needs. Always answer in a JSON format.\"\n",
    "\n",
    "def generate(\n",
    "    prompt: str,\n",
    "    json_format: Optional[JsonSchemaValue] = None,\n",
    "    model=model,\n",
    "    system_prompt=system_prompt,\n",
    ") -> str:\n",
    "    response: ChatResponse = chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        options={\n",
    "            \"num_ctx\": 4096,\n",
    "            \"num_predict\": 1024,\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 0.95,\n",
    "            \"temperature\": 0.0,\n",
    "            \"seed\": 0,  # this is not needed when temp is 0\n",
    "            \"repeat_penalty\": 1.0,  # remain default for json outputs, from experience.\n",
    "        },\n",
    "        format=json_format,\n",
    "        stream=False,\n",
    "    )\n",
    "    return response.message.content\n",
    "\n",
    "# prompt = \"give me 5 interesting facts about the universe\"\n",
    "prompt = \"Give me a simple recipe for a delicious citrusy cake. Make sure units are in grams when it makes sense. Temperatures should be in C.\"\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more control\n",
    "Now, the format is already following a JSON from the system prompt, but we cannot know beforehand what fields are inside it. Let's fix this by introducing a **schema**, a structured definition of our output.\n",
    "\n",
    "We start building our schema through a typed BaseModel in pydantic (which will be converted to a grammar-like format called GBNF, that you can read about here: <https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md>)\n",
    "\n",
    "If you were not to use ollama, you could pass a schema directly, which again will be converted to GBNF:\n",
    "\n",
    "```python\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"questions\": {\n",
    "            \"type\": \"array\",\n",
    "            \"minItems\": 1,\n",
    "            \"maxItems\": 3,\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"question\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"question\"],\n",
    "            },\n",
    "        },\n",
    "        \"score\": {\"type\": \"integer\", \"enum\": [0, 1, 2, 3]},\n",
    "        \"summary\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"questions\", \"score\", \"summary\"],\n",
    "}\n",
    "```\n",
    "\n",
    "However, the easiest and most programmatic way of handling this is define interfaces that are automatically parsed as a schema before being sent through to the llama.cpp api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Citrusy Cake Recipe',\n",
       " 'ingredients': [{'name': 'All-purpose flour',\n",
       "   'quantity': 250,\n",
       "   'unit': 'grams'},\n",
       "  {'name': 'Granulated sugar', 'quantity': 200, 'unit': 'grams'},\n",
       "  {'name': 'Unsalted butter, softened', 'quantity': 150, 'unit': 'grams'},\n",
       "  {'name': 'Egg, large', 'quantity': 2, 'unit': 'grams'},\n",
       "  {'name': 'Zest of 1 lemon', 'quantity': 20, 'unit': 'grams'},\n",
       "  {'name': 'Zest of 1 orange', 'quantity': 20, 'unit': 'grams'},\n",
       "  {'name': 'Zest of 1 lime', 'quantity': 20, 'unit': 'grams'},\n",
       "  {'name': 'Vanilla extract', 'quantity': 5, 'unit': 'grams'},\n",
       "  {'name': 'Citrus juice (e.g. lemon, orange, lime)',\n",
       "   'quantity': 100,\n",
       "   'unit': 'grams'}],\n",
       " 'instructions': [{'step': 1,\n",
       "   'description': 'Preheat the oven to 180°C (350°F). Grease two 20cm (8 inch) round cake pans and line the bottoms with parchment paper.'},\n",
       "  {'step': 2,\n",
       "   'description': 'In a medium bowl, whisk together flour, sugar, and salt.'},\n",
       "  {'step': 3,\n",
       "   'description': 'In a large bowl, using an electric mixer, beat the butter until creamy. Add the egg and beat until well combined.'},\n",
       "  {'step': 4,\n",
       "   'description': 'Gradually add the dry ingredients to the butter mixture, alternating with the citrus juice, beginning and ending with the dry ingredients. Beat just until combined.'},\n",
       "  {'step': 5,\n",
       "   'description': 'Add the lemon, orange, and lime zest and vanilla extract to the batter. Beat until well combined.'},\n",
       "  {'step': 6,\n",
       "   'description': 'Divide the batter evenly between the prepared pans and smooth the tops.'},\n",
       "  {'step': 7,\n",
       "   'description': 'Bake for 25-30 minutes, or until a toothpick inserted into the center of each cake comes out clean.'},\n",
       "  {'step': 8,\n",
       "   'description': 'Allow the cakes to cool in the pans for 5 minutes, then transfer them to a wire rack to cool completely.'},\n",
       "  {'step': 9,\n",
       "   'description': 'Once the cakes are completely cool, you can frost and decorate them as desired.'}],\n",
       " 'tools': ['electric mixer',\n",
       "  'whisk',\n",
       "  'measuring cups',\n",
       "  'spoon',\n",
       "  'parchment paper']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    quantity: float\n",
    "    unit: str\n",
    "\n",
    "class RecipeInstruction(BaseModel):\n",
    "    step: int\n",
    "    description: str\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingredients: List[Ingredient]\n",
    "    instructions: List[RecipeInstruction]\n",
    "    tools: List[str]\n",
    "\n",
    "# we can now use eval to properly format the json as an object\n",
    "# using `eval`from the output of an API is generally not safe, but we can safely do it from the JSON-output of a local model.\n",
    "eval(generate(prompt, json_format=Recipe.model_json_schema()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
