{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local LLMs and controllable outputs\n",
    "- download ollama for easy serving of models, supports all OS\n",
    "\t- https://ollama.com/download\n",
    "\t- follow the instructions and \"install\". Do not download any models yet.\n",
    "\t- this enables a CLI for running models (soon!)\n",
    "\t- in case the application doesn't start up properly, type `ollama serve` in your terminal.\n",
    "\t\t- if it's already running, you will see something like `Error: listen tcp 127.0.0.1:11434: bind: address already in use`\n",
    "\n",
    "- for local hosting, we usually prefer to run *quantized* GGUF models, named after the developer Georgi Gerganov.\n",
    "\t- the main developer for [whisper.cpp](https://github.com/ggerganov/whisper.cpp) and [llama.cpp](https://github.com/ggerganov/llama.cpp), C++ systems to run AST and LLMs respectively.\n",
    "\t- nearly all llm-applications, including ollama, is built on top of compiled binaries from llama.cpp\n",
    "\n",
    "## GGUF\n",
    "- a format that allows quantization of models.\n",
    "- typical pytorch models (or similar) can be converted to a .GGUF format.\n",
    "- these are lower bit representations of the full-precision weights used when training the networks \n",
    "\t- e.g., from FP16 (half-precision) to a ~5 bit representation, commonly denoted by the \"Q5\" suffix.\n",
    "\t\t- libraries like PyTorch train with FP32, but we've moved towards mixed-precision which combines FP32 and FP16:\n",
    "\t\t\t- FP16: weights/activations\n",
    "\t\t\t- FP32: gradients during backprop: numerical stability\n",
    "- can reduce a 70B model (140GB!!!) to 20-30GB while still being fairly usable.\n",
    "\n",
    "<p align=\"center\"> <img src=\"assets/gguf-bytes.png\" alt=\"gguf-bytes.png\"> </p>\n",
    "\n",
    "Here's a list of some quants of the Llama-3.3 70B model:\n",
    "\n",
    "<p align=\"center\"> <img src=\"assets/gguf-download.png\" alt=\"gguf-download.png\"> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting started with a model\n",
    "- Let's begin with `llama-3.2 1B` - a small 1B model just to test out our system\n",
    "- typically, there are devoted people out there that download the original models and quantize them with Llama.cpp, such that we can download the premade GGUF file.\n",
    "\t- one of the most active ones is the user `bartowski` on huggingface.\n",
    "\t\t- if you don't know of huggingface, it's basically the github of AI models and datasets\n",
    "- path: https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/blob/main/Llama-3.2-1B-Instruct-Q6_K.gguf\n",
    "- you can click \"use this model\" -> \"ollama\" that creates a runnable command:\n",
    "\t- `ollama run hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:Q6_K_L`\n",
    "\t\t- this is the 6-bit version of highest quality. It's only 1.1GB, so let's start with that.\n",
    "\n",
    "<p align=\"center\"> <img src=\"assets/huggingface-menu.png\" alt=\"hf dl menu.png\"> </p>\n",
    "\n",
    "buuuut... we're not interested in talking to it through the terminal, we want to process outputs in our code, i.e., we need an API!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama - API\n",
    "download a wrapper for the API, in this case in python\n",
    "\n",
    "`pip install ollama`\n",
    "\n",
    "we then define our model as a variable and verify its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general.architecture': 'llama', 'general.basename': 'Llama-3.2', 'general.file_type': 18, 'general.finetune': 'Instruct', 'general.languages': ['en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th'], 'general.license': 'llama3.2', 'general.parameter_count': 1235814432, 'general.quantization_version': 2, 'general.size_label': '1B', 'general.tags': ['facebook', 'meta', 'pytorch', 'llama', 'llama-3', 'text-generation'], 'general.type': 'model', 'llama.attention.head_count': 32, 'llama.attention.head_count_kv': 8, 'llama.attention.key_length': 64, 'llama.attention.layer_norm_rms_epsilon': 1e-05, 'llama.attention.value_length': 64, 'llama.block_count': 16, 'llama.context_length': 131072, 'llama.embedding_length': 2048, 'llama.feed_forward_length': 8192, 'llama.rope.dimension_count': 64, 'llama.rope.freq_base': 500000, 'llama.vocab_size': 128256, 'quantize.imatrix.chunks_count': 125, 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.entries_count': 112, 'quantize.imatrix.file': '/models_out/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.imatrix', 'tokenizer.ggml.bos_token_id': 128000, 'tokenizer.ggml.eos_token_id': 128009, 'tokenizer.ggml.merges': None, 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "model = \"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:Q6_K_L\"\n",
    "print(ollama.show(model).modelinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple recipe for a delicious citrusy cake that uses metric units and Celsius temperatures:\n",
      "\n",
      "**Lemon Blueberry Cake**\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 250g all-purpose flour\n",
      "* 150g granulated sugar\n",
      "* 100g unsalted butter, softened (approx. 115°C)\n",
      "* 2 large eggs\n",
      "* 200g plain Greek yogurt\n",
      "* 1 tsp baking powder\n",
      "* 0.5 tsp salt\n",
      "* 120g fresh blueberries\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 180°C and grease two 20cm round cake pans.\n",
      "2. In a medium bowl, whisk together the flour, sugar, baking powder, and salt.\n",
      "3. In a large mixing bowl, use an electric mixer to cream together the butter and eggs until light and fluffy (approx. 4-5 minutes).\n",
      "4. Add the yogurt and mix until well combined.\n",
      "5. Gradually add the dry ingredients to the wet ingredients, alternating with the lemon juice, starting and ending with the dry ingredients. Beat just until combined.\n",
      "6. Gently fold in the blueberries.\n",
      "7. Divide the batter evenly between the prepared pans and smooth the tops.\n",
      "8. Bake for 25-30 minutes or until a toothpick inserted into the center of each cake comes out clean.\n",
      "9. Remove from the oven and let cool in the pans for 5 minutes before transferring to a wire rack to cool completely.\n",
      "\n",
      "**Tips:**\n",
      "\n",
      "* Use fresh lemons for the best flavor.\n",
      "* Don't overmix the batter, as this can lead to a dense cake.\n",
      "* If you want a stronger lemon flavor, you can increase the amount of lemon juice to 200g or more.\n",
      "* The blueberries will release their juices during baking, so don't worry if they don't get evenly distributed in the batter.\n",
      "\n",
      "Enjoy your delicious citrusy cake!\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "model = \"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:Q6_K_L\"\n",
    "\n",
    "prompt = \"Give me a simple recipe for a delicious citrusy cake. Make sure units are in grams when it makes sense. Temperatures should be in C.\"\n",
    "\n",
    "response = chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling the responses...\n",
    "\n",
    "Sure it's cool with text from a local model, but we can't do much with it. \n",
    "Time to tame it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, there are a few common parameters that can be used to tune the outputs.\n",
    "Some are related to \"creativity\", whereas some control the predictability and determinism of the outputs.\n",
    "\n",
    "```python\n",
    "\"num_ctx\": \"Maximum number of tokens the model can process in a single input.\"\n",
    "\"seed\": \"Random seed for deterministic generation.\"\n",
    "\"num_predict\": \"Maximum number of tokens to generate in output.\"\n",
    "\"top_k\": \"Limits sampling to the top K most probable tokens.\"\n",
    "\"top_p\": \"Limits sampling to the smallest set of tokens with cumulative probability >= top_p.\"\n",
    "\"temperature\": \"Controls randomness in generation; higher values increase randomness.\"\n",
    "\"repeat_penalty\": \"Penalty for repeated tokens to reduce repetition in output.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"recipe\": {\n",
      "    \"name\": \"Citrusy Cake\",\n",
      "    \"ingredients\": [\n",
      "      {\n",
      "        \"name\": \"Flour\",\n",
      "        \"quantity\": 250g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Sugar\",\n",
      "        \"quantity\": 200g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Baking powder\",\n",
      "        \"quantity\": 5g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Salt\",\n",
      "        \"quantity\": 2g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Butter\",\n",
      "        \"quantity\": 100g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Eggs\",\n",
      "        \"quantity\": 4,\n",
      "        \"unit\": \"units\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Milk\",\n",
      "        \"quantity\": 250g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Zest of 1 orange\",\n",
      "        \"quantity\": 20g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Zest of 1 lemon\",\n",
      "        \"quantity\": 15g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Juice of 1 lemon\",\n",
      "        \"quantity\": 30g,\n",
      "        \"unit\": \"grams\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Juice of 1 orange\",\n",
      "        \"quantity\": 30g,\n",
      "        \"unit\": \"grams\"\n",
      "      }\n",
      "    ],\n",
      "    \"instructions\": [\n",
      "      {\n",
      "        \"step\": \"Preheat oven to 180°C\",\n",
      "        \"description\": \"Preheat oven to 180°C\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Mix dry ingredients\",\n",
      "        \"description\": \"Mix flour, sugar, baking powder, and salt\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Mix wet ingredients\",\n",
      "        \"description\": \"Mix butter, eggs, milk, orange zest, lemon zest, lemon juice, and orange juice\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Combine wet and dry ingredients\",\n",
      "        \"description\": \"Combine wet and dry ingredients\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Pour batter into a greased cake pan\",\n",
      "        \"description\": \"Pour batter into a greased cake pan\"\n",
      "      },\n",
      "      {\n",
      "        \"step\": \"Bake for 35-40 minutes\",\n",
      "        \"description\": \"Bake for 35-40 minutes\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ollama import ChatResponse\n",
    "from ollama import chat\n",
    "from pydantic.types import JsonSchemaValue\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "model = \"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:Q6_K_L\"\n",
    "\n",
    "system_prompt = \"You are a helpful assistant that provides clear and concise answers to the user's needs. Always answer in a JSON format.\"\n",
    "\n",
    "\n",
    "def generate(\n",
    "    prompt: str,\n",
    "    json_format: Optional[JsonSchemaValue] = None,\n",
    "    model=model,\n",
    "    system_prompt=system_prompt,\n",
    ") -> str:\n",
    "    response: ChatResponse = chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        options={\n",
    "            \"num_ctx\": 4096,\n",
    "            \"num_predict\": 1024,\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 0.95,\n",
    "            \"temperature\": 0.0,\n",
    "            \"seed\": 0,  # this is not needed when temp is 0\n",
    "            \"repeat_penalty\": 1.0,  # remain default for json outputs, from experience.\n",
    "        },\n",
    "        format=json_format,\n",
    "        stream=False,\n",
    "    )\n",
    "    return response.message.content\n",
    "\n",
    "# prompt = \"give me 5 interesting facts about the universe\"\n",
    "prompt = \"Give me a simple recipe for a delicious citrusy cake. Make sure units are in grams when it makes sense. Temperatures should be in C.\"\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More control!\n",
    "Now, the format is already following a JSON from the system prompt, but we cannot know beforehand what fields are inside it. Let's fix this by introducing a **schema**, a structured definition of our output.\n",
    "(Note also that it responds with a triple-tick markdown style bracket, indicating a code snippet inserted into markdown. This can be circumvented by postprocessing, however.)\n",
    "\n",
    "We start building our schema through a typed BaseModel in pydantic (which will be converted to a grammar-like format called GBNF, as we'll see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Citrusy Cake Recipe',\n",
       " 'ingredients': [{'name': 'All-purpose flour',\n",
       "   'quantity': 250,\n",
       "   'unit': 'grams'},\n",
       "  {'name': 'Granulated sugar', 'quantity': 200, 'unit': 'grams'},\n",
       "  {'name': 'Unsalted butter, softened', 'quantity': 150, 'unit': 'grams'},\n",
       "  {'name': 'Egg, large', 'quantity': 2, 'unit': 'grams'},\n",
       "  {'name': 'Zest of 1 lemon', 'quantity': 20, 'unit': 'grams'},\n",
       "  {'name': 'Zest of 1 orange', 'quantity': 20, 'unit': 'grams'},\n",
       "  {'name': 'Zest of 1 lime', 'quantity': 20, 'unit': 'grams'},\n",
       "  {'name': 'Vanilla extract', 'quantity': 5, 'unit': 'grams'},\n",
       "  {'name': 'Citrus juice (e.g. lemon, orange, lime)',\n",
       "   'quantity': 100,\n",
       "   'unit': 'grams'}],\n",
       " 'instructions': [{'step': 1,\n",
       "   'description': 'Preheat the oven to 180°C (350°F). Grease two 20cm (8 inch) round cake pans and line the bottoms with parchment paper.'},\n",
       "  {'step': 2,\n",
       "   'description': 'In a medium bowl, whisk together flour, sugar, and salt.'},\n",
       "  {'step': 3,\n",
       "   'description': 'In a large bowl, using an electric mixer, beat the butter until creamy. Add the egg and beat until well combined.'},\n",
       "  {'step': 4,\n",
       "   'description': 'Gradually add the dry ingredients to the butter mixture, alternating with the citrus juice, beginning and ending with the dry ingredients. Beat just until combined.'},\n",
       "  {'step': 5,\n",
       "   'description': 'Add the lemon, orange, and lime zest and vanilla extract to the batter. Beat until well combined.'},\n",
       "  {'step': 6,\n",
       "   'description': 'Divide the batter evenly between the prepared pans and smooth the tops.'},\n",
       "  {'step': 7,\n",
       "   'description': 'Bake for 25-30 minutes, or until a toothpick inserted into the center of each cake comes out clean.'},\n",
       "  {'step': 8,\n",
       "   'description': 'Allow the cakes to cool in the pans for 5 minutes, then transfer them to a wire rack to cool completely.'},\n",
       "  {'step': 9,\n",
       "   'description': 'Once the cakes are completely cool, you can frost and decorate them as desired.'}],\n",
       " 'tools': ['electric mixer',\n",
       "  'whisk',\n",
       "  'measuring cups',\n",
       "  'spoon',\n",
       "  'parchment paper']}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    quantity: float\n",
    "    unit: str\n",
    "\n",
    "class RecipeInstruction(BaseModel):\n",
    "    step: int\n",
    "    description: str\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingredients: List[Ingredient]\n",
    "    instructions: List[RecipeInstruction]\n",
    "    tools: List[str]\n",
    "\n",
    "# we can now use eval to properly format the json as an object\n",
    "# using `eval`from the output of an API is generally not safe, but we can safely do it from the JSON-output of a local model.\n",
    "eval(generate(prompt, json_format=Recipe.model_json_schema()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
